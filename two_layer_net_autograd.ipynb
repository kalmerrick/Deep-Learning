{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Tensors and autograd\n",
    "-------------------------------\n",
    "\n",
    "A fully-connected ReLU network with one hidden layer and no biases, trained to\n",
    "predict y from x by minimizing squared Euclidean distance.\n",
    "\n",
    "This implementation computes the forward pass using operations on PyTorch\n",
    "Tensors, and uses PyTorch autograd to compute gradients.\n",
    "\n",
    "\n",
    "A PyTorch Tensor represents a node in a computational graph. If ``x`` is a\n",
    "Tensor that has ``x.requires_grad=True`` then ``x.grad`` is another Tensor\n",
    "holding the gradient of ``x`` with respect to some scalar value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27474704.0\n",
      "1 22330140.0\n",
      "2 23600544.0\n",
      "3 27958116.0\n",
      "4 32199080.0\n",
      "5 31709912.0\n",
      "6 25043572.0\n",
      "7 15293150.0\n",
      "8 7846143.5\n",
      "9 3789707.0\n",
      "10 1991932.625\n",
      "11 1217223.875\n",
      "12 861286.375\n",
      "13 671950.5625\n",
      "14 553402.9375\n",
      "15 468706.03125\n",
      "16 402946.65625\n",
      "17 349473.125\n",
      "18 304871.3125\n",
      "19 267170.875\n",
      "20 235213.78125\n",
      "21 207819.578125\n",
      "22 184179.671875\n",
      "23 163682.5\n",
      "24 145844.734375\n",
      "25 130260.46875\n",
      "26 116615.3046875\n",
      "27 104618.3515625\n",
      "28 94040.0\n",
      "29 84690.7265625\n",
      "30 76407.7109375\n",
      "31 69046.609375\n",
      "32 62495.8203125\n",
      "33 56659.8046875\n",
      "34 51450.01953125\n",
      "35 46784.12109375\n",
      "36 42600.71484375\n",
      "37 38843.14453125\n",
      "38 35460.13671875\n",
      "39 32410.9140625\n",
      "40 29658.623046875\n",
      "41 27168.87109375\n",
      "42 24914.515625\n",
      "43 22871.806640625\n",
      "44 21018.744140625\n",
      "45 19335.005859375\n",
      "46 17802.59375\n",
      "47 16406.576171875\n",
      "48 15134.1123046875\n",
      "49 13972.43359375\n",
      "50 12909.6796875\n",
      "51 11937.19140625\n",
      "52 11046.666015625\n",
      "53 10230.4189453125\n",
      "54 9481.30859375\n",
      "55 8793.6806640625\n",
      "56 8161.458984375\n",
      "57 7580.62158203125\n",
      "58 7045.541015625\n",
      "59 6552.29052734375\n",
      "60 6097.357421875\n",
      "61 5677.2646484375\n",
      "62 5289.18994140625\n",
      "63 4930.43603515625\n",
      "64 4598.46044921875\n",
      "65 4291.09375\n",
      "66 4006.334228515625\n",
      "67 3742.153564453125\n",
      "68 3497.101806640625\n",
      "69 3269.509033203125\n",
      "70 3058.08984375\n",
      "71 2861.544677734375\n",
      "72 2678.70947265625\n",
      "73 2508.59375\n",
      "74 2350.166748046875\n",
      "75 2202.605712890625\n",
      "76 2064.99365234375\n",
      "77 1936.734130859375\n",
      "78 1817.03955078125\n",
      "79 1705.32177734375\n",
      "80 1600.964111328125\n",
      "81 1503.6212158203125\n",
      "82 1412.6685791015625\n",
      "83 1327.5770263671875\n",
      "84 1247.9837646484375\n",
      "85 1173.5447998046875\n",
      "86 1103.83056640625\n",
      "87 1038.5531005859375\n",
      "88 977.3519287109375\n",
      "89 919.9864501953125\n",
      "90 866.2034301757812\n",
      "91 815.7564086914062\n",
      "92 768.453125\n",
      "93 724.0374755859375\n",
      "94 682.3438110351562\n",
      "95 643.1774291992188\n",
      "96 606.4065551757812\n",
      "97 571.843017578125\n",
      "98 539.3637084960938\n",
      "99 508.8370056152344\n",
      "100 480.1147766113281\n",
      "101 453.0979309082031\n",
      "102 427.68377685546875\n",
      "103 403.7738342285156\n",
      "104 381.2803039550781\n",
      "105 360.10302734375\n",
      "106 340.16241455078125\n",
      "107 321.3819580078125\n",
      "108 303.67626953125\n",
      "109 286.99444580078125\n",
      "110 271.27020263671875\n",
      "111 256.4462890625\n",
      "112 242.46719360351562\n",
      "113 229.2847900390625\n",
      "114 216.85101318359375\n",
      "115 205.12046813964844\n",
      "116 194.0485076904297\n",
      "117 183.59820556640625\n",
      "118 173.73202514648438\n",
      "119 164.42286682128906\n",
      "120 155.63023376464844\n",
      "121 147.32461547851562\n",
      "122 139.478759765625\n",
      "123 132.0665283203125\n",
      "124 125.06385803222656\n",
      "125 118.44552612304688\n",
      "126 112.19107818603516\n",
      "127 106.27831268310547\n",
      "128 100.69076538085938\n",
      "129 95.40555572509766\n",
      "130 90.4074935913086\n",
      "131 85.67890930175781\n",
      "132 81.20499420166016\n",
      "133 76.97479248046875\n",
      "134 72.97029876708984\n",
      "135 69.181640625\n",
      "136 65.5968017578125\n",
      "137 62.20450973510742\n",
      "138 58.99181365966797\n",
      "139 55.94976806640625\n",
      "140 53.06916046142578\n",
      "141 50.34090042114258\n",
      "142 47.75819778442383\n",
      "143 45.31263732910156\n",
      "144 42.99447250366211\n",
      "145 40.80024337768555\n",
      "146 38.719154357910156\n",
      "147 36.74756622314453\n",
      "148 34.87949752807617\n",
      "149 33.108619689941406\n",
      "150 31.431127548217773\n",
      "151 29.840848922729492\n",
      "152 28.333038330078125\n",
      "153 26.902761459350586\n",
      "154 25.546138763427734\n",
      "155 24.26066780090332\n",
      "156 23.04102897644043\n",
      "157 21.88421630859375\n",
      "158 20.787107467651367\n",
      "159 19.746814727783203\n",
      "160 18.758647918701172\n",
      "161 17.82171630859375\n",
      "162 16.933168411254883\n",
      "163 16.089767456054688\n",
      "164 15.289069175720215\n",
      "165 14.528861045837402\n",
      "166 13.807761192321777\n",
      "167 13.123306274414062\n",
      "168 12.473457336425781\n",
      "169 11.85634994506836\n",
      "170 11.270576477050781\n",
      "171 10.714335441589355\n",
      "172 10.186051368713379\n",
      "173 9.684270858764648\n",
      "174 9.208218574523926\n",
      "175 8.755541801452637\n",
      "176 8.325545310974121\n",
      "177 7.917708396911621\n",
      "178 7.529867172241211\n",
      "179 7.161508560180664\n",
      "180 6.811331272125244\n",
      "181 6.478654861450195\n",
      "182 6.162525177001953\n",
      "183 5.862242221832275\n",
      "184 5.576805114746094\n",
      "185 5.305538654327393\n",
      "186 5.047557830810547\n",
      "187 4.802414894104004\n",
      "188 4.569520473480225\n",
      "189 4.348055839538574\n",
      "190 4.137567520141602\n",
      "191 3.9374425411224365\n",
      "192 3.747068405151367\n",
      "193 3.566138505935669\n",
      "194 3.3943142890930176\n",
      "195 3.23049259185791\n",
      "196 3.074887752532959\n",
      "197 2.9269111156463623\n",
      "198 2.786316394805908\n",
      "199 2.6524524688720703\n",
      "200 2.5250515937805176\n",
      "201 2.40405535697937\n",
      "202 2.2888023853302\n",
      "203 2.1792213916778564\n",
      "204 2.074993133544922\n",
      "205 1.9758230447769165\n",
      "206 1.881371259689331\n",
      "207 1.7915878295898438\n",
      "208 1.7061347961425781\n",
      "209 1.624729871749878\n",
      "210 1.5474159717559814\n",
      "211 1.473606824874878\n",
      "212 1.4036402702331543\n",
      "213 1.3369771242141724\n",
      "214 1.2734400033950806\n",
      "215 1.2130663394927979\n",
      "216 1.1555781364440918\n",
      "217 1.10075044631958\n",
      "218 1.048617959022522\n",
      "219 0.9989912509918213\n",
      "220 0.9518007040023804\n",
      "221 0.9067855477333069\n",
      "222 0.8640106916427612\n",
      "223 0.8231654167175293\n",
      "224 0.7843106985092163\n",
      "225 0.7473238706588745\n",
      "226 0.7121642231941223\n",
      "227 0.6786729097366333\n",
      "228 0.6467605829238892\n",
      "229 0.6163389086723328\n",
      "230 0.58737713098526\n",
      "231 0.559782087802887\n",
      "232 0.533500611782074\n",
      "233 0.508573055267334\n",
      "234 0.4847714900970459\n",
      "235 0.46203485131263733\n",
      "236 0.44044002890586853\n",
      "237 0.419803649187088\n",
      "238 0.40017837285995483\n",
      "239 0.38149139285087585\n",
      "240 0.36366674304008484\n",
      "241 0.34670183062553406\n",
      "242 0.3305615484714508\n",
      "243 0.31519147753715515\n",
      "244 0.30039626359939575\n",
      "245 0.2864367961883545\n",
      "246 0.27312007546424866\n",
      "247 0.26048582792282104\n",
      "248 0.2484080046415329\n",
      "249 0.23684248328208923\n",
      "250 0.22586631774902344\n",
      "251 0.2153846174478531\n",
      "252 0.20536519587039948\n",
      "253 0.1958131641149521\n",
      "254 0.18673394620418549\n",
      "255 0.17812100052833557\n",
      "256 0.16985365748405457\n",
      "257 0.1620287299156189\n",
      "258 0.1545230895280838\n",
      "259 0.14736227691173553\n",
      "260 0.14057429134845734\n",
      "261 0.13407795131206512\n",
      "262 0.12788259983062744\n",
      "263 0.12199419736862183\n",
      "264 0.11641284823417664\n",
      "265 0.11102920770645142\n",
      "266 0.10592765361070633\n",
      "267 0.10103224962949753\n",
      "268 0.09636969864368439\n",
      "269 0.0919625535607338\n",
      "270 0.08775300532579422\n",
      "271 0.0837080255150795\n",
      "272 0.0798715353012085\n",
      "273 0.07619154453277588\n",
      "274 0.07269026339054108\n",
      "275 0.06937647610902786\n",
      "276 0.0662049651145935\n",
      "277 0.06315970420837402\n",
      "278 0.060279086232185364\n",
      "279 0.05751688405871391\n",
      "280 0.05488666146993637\n",
      "281 0.052368663251399994\n",
      "282 0.04996629059314728\n",
      "283 0.047684162855148315\n",
      "284 0.04551505297422409\n",
      "285 0.04343528673052788\n",
      "286 0.04145531728863716\n",
      "287 0.03958367556333542\n",
      "288 0.03776995465159416\n",
      "289 0.036069802939891815\n",
      "290 0.03442429378628731\n",
      "291 0.03286255523562431\n",
      "292 0.031373608857393265\n",
      "293 0.029956689104437828\n",
      "294 0.028604179620742798\n",
      "295 0.02730189636349678\n",
      "296 0.026072559878230095\n",
      "297 0.024899307638406754\n",
      "298 0.02376769855618477\n",
      "299 0.022698231041431427\n",
      "300 0.02166915498673916\n",
      "301 0.020695684477686882\n",
      "302 0.019767502322793007\n",
      "303 0.018881257623434067\n",
      "304 0.018025340512394905\n",
      "305 0.01721774972975254\n",
      "306 0.016458740457892418\n",
      "307 0.015724627301096916\n",
      "308 0.015021907165646553\n",
      "309 0.014349407516419888\n",
      "310 0.013713009655475616\n",
      "311 0.013100341893732548\n",
      "312 0.0125249233096838\n",
      "313 0.01196796540170908\n",
      "314 0.011433948762714863\n",
      "315 0.010932529345154762\n",
      "316 0.010448571294546127\n",
      "317 0.00998776126652956\n",
      "318 0.009546728804707527\n",
      "319 0.009128260426223278\n",
      "320 0.008731788955628872\n",
      "321 0.008356854319572449\n",
      "322 0.00798816792666912\n",
      "323 0.00764082046225667\n",
      "324 0.0073061189614236355\n",
      "325 0.006992039270699024\n",
      "326 0.006688553839921951\n",
      "327 0.006400649435818195\n",
      "328 0.006129834800958633\n",
      "329 0.005864791106432676\n",
      "330 0.005617888178676367\n",
      "331 0.005375982262194157\n",
      "332 0.005151469726115465\n",
      "333 0.004934384487569332\n",
      "334 0.004723815713077784\n",
      "335 0.0045207408256828785\n",
      "336 0.004336640238761902\n",
      "337 0.0041611939668655396\n",
      "338 0.003988091368228197\n",
      "339 0.003825899912044406\n",
      "340 0.003668231889605522\n",
      "341 0.003517096396535635\n",
      "342 0.003373604267835617\n",
      "343 0.0032364039216190577\n",
      "344 0.0031083400826901197\n",
      "345 0.0029824525117874146\n",
      "346 0.0028637140057981014\n",
      "347 0.0027497417759150267\n",
      "348 0.0026407004334032536\n",
      "349 0.002537814201787114\n",
      "350 0.0024383291602134705\n",
      "351 0.0023408804554492235\n",
      "352 0.002252396894618869\n",
      "353 0.0021662116050720215\n",
      "354 0.002081929938867688\n",
      "355 0.002002457622438669\n",
      "356 0.00192799954675138\n",
      "357 0.0018552199471741915\n",
      "358 0.0017865253612399101\n",
      "359 0.0017198862042278051\n",
      "360 0.00165641400963068\n",
      "361 0.0015942795434966683\n",
      "362 0.0015360784018412232\n",
      "363 0.001481953077018261\n",
      "364 0.0014278882881626487\n",
      "365 0.0013780285371467471\n",
      "366 0.001329846796579659\n",
      "367 0.001283386256545782\n",
      "368 0.0012380557600408792\n",
      "369 0.0011969087645411491\n",
      "370 0.0011539782863110304\n",
      "371 0.001114570302888751\n",
      "372 0.0010743595194071531\n",
      "373 0.0010391054674983025\n",
      "374 0.0010047185933217406\n",
      "375 0.0009705413831397891\n",
      "376 0.0009390240302309394\n",
      "377 0.000909391266759485\n",
      "378 0.0008794226450845599\n",
      "379 0.0008503771969117224\n",
      "380 0.0008235238492488861\n",
      "381 0.0007956601912155747\n",
      "382 0.0007709752535447478\n",
      "383 0.0007476650062017143\n",
      "384 0.0007239921251311898\n",
      "385 0.0007024352089501917\n",
      "386 0.0006803892902098596\n",
      "387 0.0006589353433810174\n",
      "388 0.00063921301625669\n",
      "389 0.000620366248767823\n",
      "390 0.0006014667451381683\n",
      "391 0.0005831902381032705\n",
      "392 0.0005666738725267351\n",
      "393 0.0005506918532773852\n",
      "394 0.0005351561703719199\n",
      "395 0.0005195023841224611\n",
      "396 0.0005050095496699214\n",
      "397 0.0004906977410428226\n",
      "398 0.00047654713853262365\n",
      "399 0.0004625985457096249\n",
      "400 0.0004508118727244437\n",
      "401 0.00043840607395395637\n",
      "402 0.0004256951797287911\n",
      "403 0.0004140807141084224\n",
      "404 0.0004037432372570038\n",
      "405 0.0003931858518626541\n",
      "406 0.00038309901719912887\n",
      "407 0.0003731592441909015\n",
      "408 0.0003631412982940674\n",
      "409 0.0003536432923283428\n",
      "410 0.00034499005414545536\n",
      "411 0.00033626260119490325\n",
      "412 0.00032787167583592236\n",
      "413 0.00032059531076811254\n",
      "414 0.00031301952549256384\n",
      "415 0.0003051164676435292\n",
      "416 0.00029689117218367755\n",
      "417 0.00029060355154797435\n",
      "418 0.00028294860385358334\n",
      "419 0.00027660871273837984\n",
      "420 0.0002705566876102239\n",
      "421 0.00026437919586896896\n",
      "422 0.00025784430908970535\n",
      "423 0.0002516746462788433\n",
      "424 0.0002469196333549917\n",
      "425 0.0002406738931313157\n",
      "426 0.0002352805604459718\n",
      "427 0.0002304561494383961\n",
      "428 0.0002250447141705081\n",
      "429 0.00022035831352695823\n",
      "430 0.00021544838091358542\n",
      "431 0.0002107976470142603\n",
      "432 0.00020636034605558962\n",
      "433 0.0002018175582634285\n",
      "434 0.0001978908258024603\n",
      "435 0.0001938431232701987\n",
      "436 0.00019004661589860916\n",
      "437 0.0001857074094004929\n",
      "438 0.0001823267957661301\n",
      "439 0.00017857000057119876\n",
      "440 0.00017478609515819699\n",
      "441 0.0001716730766929686\n",
      "442 0.0001685725583229214\n",
      "443 0.00016488280380144715\n",
      "444 0.00016171965398825705\n",
      "445 0.00015887126210145652\n",
      "446 0.0001558104413561523\n",
      "447 0.00015312794130295515\n",
      "448 0.00015051908849272877\n",
      "449 0.00014726573135703802\n",
      "450 0.00014440833183471113\n",
      "451 0.00014152165385894477\n",
      "452 0.00013907483662478626\n",
      "453 0.00013654466602019966\n",
      "454 0.0001340290327789262\n",
      "455 0.0001314729597652331\n",
      "456 0.0001290375366806984\n",
      "457 0.0001270929933525622\n",
      "458 0.0001248396438313648\n",
      "459 0.00012211342982482165\n",
      "460 0.00011986668687313795\n",
      "461 0.00011812159937107936\n",
      "462 0.00011602213635342196\n",
      "463 0.00011441198148531839\n",
      "464 0.00011252939293626696\n",
      "465 0.00011093720240751281\n",
      "466 0.00010875624866457656\n",
      "467 0.00010696789831854403\n",
      "468 0.00010517278860788792\n",
      "469 0.0001036485264194198\n",
      "470 0.00010228091559838504\n",
      "471 0.00010050182754639536\n",
      "472 9.921000309986994e-05\n",
      "473 9.750915342010558e-05\n",
      "474 9.597177268005908e-05\n",
      "475 9.445417526876554e-05\n",
      "476 9.285569831263274e-05\n",
      "477 9.142437920672819e-05\n",
      "478 9.003153536468744e-05\n",
      "479 8.894911297829822e-05\n",
      "480 8.727478416403756e-05\n",
      "481 8.611092926003039e-05\n",
      "482 8.467039151582867e-05\n",
      "483 8.317983156302944e-05\n",
      "484 8.20311761344783e-05\n",
      "485 8.103435538941994e-05\n",
      "486 7.967975398059934e-05\n",
      "487 7.870455010561273e-05\n",
      "488 7.74926011217758e-05\n",
      "489 7.639580871909857e-05\n",
      "490 7.567679131170735e-05\n",
      "491 7.445233495673165e-05\n",
      "492 7.350965461228043e-05\n",
      "493 7.239038677653298e-05\n",
      "494 7.13033223291859e-05\n",
      "495 7.050132262520492e-05\n",
      "496 6.958187441341579e-05\n",
      "497 6.853549712104723e-05\n",
      "498 6.772307096980512e-05\n",
      "499 6.673656753264368e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# dtype = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Tensors during the backward pass.\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Create random Tensors for weights.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y using operations on Tensors; these\n",
    "    # are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the a scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    # An alternative way is to operate on weight.data and weight.grad.data.\n",
    "    # Recall that tensor.data gives a tensor that shares the storage with\n",
    "    # tensor, but doesn't track history.\n",
    "    # You can also use torch.optim.SGD to achieve this.\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
